{
 "metadata": {
  "name": "Classifier"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import os\n",
      "rootdir = \"/home/vicky/DataSets/DynamicQueryExpansion/April/messageSurrogates/\"\n",
      "files = os.listdir(\"/home/vicky/DataSets/DynamicQueryExpansion/April/messageSurrogates\")\n",
      "wrngsfile = open(\"/home/vicky/DataSets/DynamicQueryExpansion/April/aprilwarnings.txt\")\n",
      "wrngs = [json.loads(k) for k in wrngsfile]\n",
      "wdids = []\n",
      "[wdids + k[\"derivedFrom\"][\"derivedIds\"] for k in wrngs]\n",
      "print len(wdids)\n",
      "ls = []\n",
      "for k in files:\n",
      "    with open(rootdir + k) as f:\n",
      "        for l in f:\n",
      "            if l.strip():\n",
      "                j= json.loads(l)\n",
      "                ls.append(j)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twwarnings = []\n",
      "print len(ls)\n",
      "print len([k for k in ls if k])\n",
      "tlens = []\n",
      "for k in ls:\n",
      "    if k:\n",
      "        for w in k:\n",
      "            nw = w.copy()\n",
      "            text = \"\"\n",
      "            #print w[\"derivedFrom\"].keys()\n",
      "            i = 0\n",
      "            for txt in w[\"derivedFrom\"][\"derivedTws\"]:\n",
      "                i += 1\n",
      "                text += \". \" + \" \".join([j[\"lemma\"] for j in txt[\"BasisEnrichment\"][\"tokens\"]])\n",
      "            #del(nw[\"derivedFrom\"][\"derivedTws\"])\n",
      "            tlens.append(i)\n",
      "            nw[\"derivedFrom\"][\"tweetText\"] = text\n",
      "            twwarnings.append(nw)\n",
      "print len(twwarnings)\n",
      "print len([k for k in twwarnings if k])\n",
      "print min(tlens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "290\n",
        "182\n",
        "452"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "452\n",
        "2\n"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"/home/vicky/DataSets/DynamicQueryExpansion/aprilWarningswithText.txt\", \"w\") as out:\n",
      "    cnt = 0\n",
      "    for k in twwarnings:\n",
      "        cnt += 1\n",
      "        out.write(json.dumps(k, ensure_ascii=False).encode(\"utf-8\") + \"\\n\")\n",
      "    print cnt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "452\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twwarnings[1][\"model\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "u'Local Modularity Spatial Scan(classifier=classification.randomforest-CU v0.0.1)'"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist_popln = {}\n",
      "for k in twwarnings:\n",
      "    fdist_popln.setdefault(k[\"population\"], 0)\n",
      "    fdist_popln[k[\"population\"]] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "alphab = fdist_popln.keys()\n",
      "frequencies = [fdist_popln[k] for k in alphab]\n",
      "\n",
      "pos = np.arange(len(alphab))\n",
      "width = 1.0     # gives histogram aspect to the bar diagram\n",
      "\n",
      "ax = plt.axes()\n",
      "ax.set_xticks(pos + (width / 2))\n",
      "ax.set_xticklabels(alphab)\n",
      "\n",
      "plt.bar(pos, frequencies, width, color='r')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "#print sys.path\n",
      "sys.path.extend([\"/home/vicky/workspace/CACI_integration/cu-evaluations/scratch/civilUnrest\", \"/home/vicky/workspace/CACI_integration/scratch/twitter\",\"/home/vicky/workspace/CACI_integration/scratch/\" ])\n",
      "import newtweetprobclassifier as nc\n",
      "reload(nc)\n",
      "#from newtweetprobclassifier import TweetClassifier, Densifier \n",
      "#reload(newtweetprobclassifier)\n",
      "clf = nc.TweetClassifier.load()\n",
      "#dir(clf)\n",
      "#import utils\n",
      "#print utils.CIVIL_UNREST_OSI_CODES\n",
      "print nc.CIVIL_UNREST_OSI_CODES"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['011', '012', '013', '014', '015', '016']\n"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = clf.predict_classproba(twwarnings[21][\"derivedFrom\"][\"tweetText\"])\n",
      "print arr\n",
      "#EVCODES = [\"011\", \"012\", \"013\", \"014\", \"015\", \"016\"]\n",
      "##POPULATION_TYPE_CODES = {\n",
      "#    '01': \"General Population\",\n",
      "#    '02': \"Business\",\n",
      "#    '03': \"Ethnic\",\n",
      "#   '04': \"Legal\",\n",
      "#   '05': \"Education\",\n",
      "#    '06': \"Religious\",\n",
      "#    '07': \"Medical\",\n",
      "#   '08': \"Media\",\n",
      "#   '09': \"Labor\",\n",
      "#   '10': \"Refugees/Displaced\",\n",
      "#   '11': \"Agricultural\"\n",
      "#\n",
      "#POPLN_CODES = [k[1] for k in sorted(POPULATION_TYPE_CODES.items(), key=lambda x: x[0])]\n",
      "#print POPLN_CODES\n",
      "#op = zip(POPLN_CODES, arr[2])\n",
      "#sorted(pop, key=lambda x: x[1],  reverse=True)[:2]\n",
      "#clf.clf_e.__dict__[\"named_steps\"][\"classifier\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "({'011': 0.0, '012': 0.0, '013': 0.0, '014': 0.0, '015': 0.24723390343395374, '016': 0.75276609656604621}, {'1': 1.0, '2': 0.0}, {'Business': 0.0, 'Media': 0.0, 'Medical': 0.023809523809523728, 'Legal': 0.0, 'General Population': 0.73809523809523903, 'Refugees/Displaced': 0.0, 'Ethnic': 0.023809523809523728, 'Labor': 0.14285714285714243, 'Agricultural': 0.0, 'Education': 0.071428571428571216, 'Religious': 0.0})\n"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/vicky/workspace/git/embers/data/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/vicky/workspace/git/embers/data\n"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = open(\"may_v2_gsr.data\")\n",
      "gsr = [json.loads(k.decode(\"utf-8\")) for k in a]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gsrcu = [k for k in gsr if k[\"eventType\"][:2] == \"01\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(gsrcu)\n",
      "from datetime import datetime\n",
      "def toDate(dt):\n",
      "    return datetime.strptime(dt[:10], \"%Y-%m-%d\")\n",
      "gsrcu2013 = [k for k in gsrcu if toDate(k[\"eventDate\"]) >= toDate(\"2013-01-01\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(gsrcu2013)\n",
      "from unidecode import unidecode\n",
      "gsrcu2013 = [k for k in gsrcu2013 if unidecode(k[\"location\"][0]).lower() == \"venezuela\"]\n",
      "janStatsmx_evt = dict()\n",
      "janStatsmx_pop = dict()\n",
      "\n",
      "for k in gsrcu2013:\n",
      "    if toDate(k[\"eventDate\"]) < toDate(\"2013-01-31\"):\n",
      "        s = (k[\"eventType\"].title(),k[\"population\"].title())\n",
      "        janStatsmx_evt.setdefault(s[0], 0)\n",
      "        janStatsmx_evt[s[0]] += 1\n",
      "        janStatsmx_pop.setdefault(s[1], 0)\n",
      "        janStatsmx_pop[s[1]] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(gsrcu2013)\n",
      "febStatsmx_evt = dict()\n",
      "febStatsmx_pop = dict()\n",
      "for k in gsrcu2013:\n",
      "    if toDate(\"2013-02-01\") <= toDate(k[\"eventDate\"]) < toDate(\"2013-02-28\"):\n",
      "        s = (k[\"eventType\"].title(),k[\"population\"].title())\n",
      "        febStatsmx_evt.setdefault(s[0], 0)\n",
      "        febStatsmx_evt[s[0]] += 1\n",
      "        febStatsmx_pop.setdefault(s[1], 0)\n",
      "        febStatsmx_pop[s[1]] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 250
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(gsrcu2013)\n",
      "marchStatsmx_evt = dict()\n",
      "marchStatsmx_pop = dict()\n",
      "for k in gsrcu2013:\n",
      "    if toDate(\"2013-03-01\") <= toDate(k[\"eventDate\"]) < toDate(\"2013-03-31\"):\n",
      "        s = (k[\"eventType\"].title(),k[\"population\"].title())\n",
      "        marchStatsmx_evt.setdefault(s[0], 0)\n",
      "        marchStatsmx_evt[s[0]] += 1\n",
      "        marchStatsmx_pop.setdefault(s[1], 0)\n",
      "        marchStatsmx_pop[s[1]] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(gsrcu2013)\n",
      "aprStatsmx_evt = dict()\n",
      "aprStatsmx_pop = dict()\n",
      "for k in gsrcu2013:\n",
      "    if toDate(\"2013-04-01\") <= toDate(k[\"eventDate\"]) < toDate(\"2013-04-30\"):\n",
      "        s = (k[\"eventType\"].title(),k[\"population\"].title())\n",
      "        aprStatsmx_evt.setdefault(s[0], 0)\n",
      "        aprStatsmx_evt[s[0]] += 1\n",
      "        aprStatsmx_pop.setdefault(s[1], 0)\n",
      "        aprStatsmx_pop[s[1]] += 1\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out = open(\"gsrDistribution_evt.txt\", \"w\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out.write(\"January \\n\\n\\n\")\n",
      "for k in janStatsmx_evt:\n",
      "    out.write(str(k).replace(\",\", \" | \") + \", \" + str(janStatsmx_evt[k]) + \"\\n\")\n",
      "\n",
      "out.write(\"\\n\\n February \\n\\n\")\n",
      "for k in febStatsmx_evt:\n",
      "    out.write(str(k).replace(\",\", \" | \")  + \", \" + str(febStatsmx_evt[k]) + \"\\n\")\n",
      "    \n",
      "out.write(\"\\n\\n March \\n\\n\")\n",
      "for k in marchStatsmx_evt:\n",
      "    out.write(str(k).replace(\",\", \" | \")  + \", \" + str(marchStatsmx_evt[k]) + \"\\n\")\n",
      "\n",
      "out.write(\"\\n\\n April \\n\\n\")\n",
      "for k in aprStatsmx_evt:\n",
      "    out.write(str(k).replace(\",\", \" | \")  + \", \" + str(aprStatsmx_evt[k]) + \"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out = open(\"gsrDistribution_pop.txt\", \"w\")\n",
      "out.write(\"January \\n\\n\\n\")\n",
      "for k in janStatsmx_pop:\n",
      "    out.write(str(k).replace(\",\", \" | \") + \", \" + str(janStatsmx_pop[k]) + \"\\n\")\n",
      "\n",
      "out.write(\"\\n\\n February \\n\\n\")\n",
      "for k in febStatsmx_pop:\n",
      "    out.write(str(k).replace(\",\", \" | \")  + \", \" + str(febStatsmx_pop[k]) + \"\\n\")\n",
      "    \n",
      "out.write(\"\\n\\n March \\n\\n\")\n",
      "for k in marchStatsmx_pop:\n",
      "    out.write(str(k).replace(\",\", \" | \")  + \", \" + str(marchStatsmx_pop[k]) + \"\\n\")\n",
      "\n",
      "out.write(\"\\n\\n April \\n\\n\")\n",
      "for k in aprStatsmx_pop:\n",
      "    out.write(str(k).replace(\",\", \" | \")  + \", \" + str(aprStatsmx_pop[k]) + \"\\n\")\n",
      "\n",
      "out.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}